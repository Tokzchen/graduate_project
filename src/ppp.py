# æµ‹è¯•ç”¨ä¾‹
import re

import jieba
from bs4 import BeautifulSoup

from main.bayes_topic_scrawling import BayesTopicScrawling

test_html = """
<html>
    <body>
        <h1>æš´&amp;é›¨ç¾&#å®³;é¢„è­¦</h1>
        <script>const data = 'AIå¤§æ¨¡å‹';</script>
        <p>äººå·¥æ™ºèƒ½å¤§æ¨¡å‹åº”å¯¹å¤©æ°”å˜åŒ–</p>
        <img alt="AIå¤§æ¨¡å‹åˆ†ææš´é›¨ç¾å®³">
        <div>æš´é›¨ç¾å®³è¶Šæ¥è¶Šä¸¥é‡</div>
</body>
</html>
"""

keywords = ["æš´é›¨ç¾å®³", "å»ºç­‘ç‰©",'è¶Šæ¥è¶Šä¸¥']
for kw in keywords:
    jieba.add_word(kw, freq=100000)
def check_html_exist_kw(html, keywords):
    # ä½¿ç”¨BeautifulSoupæå–å¯è§æ–‡æœ¬ï¼ˆè‡ªåŠ¨å¤„ç†HTMLå®ä½“ï¼‰
    soup = BeautifulSoup(html, 'html.parser')

    # ç§»é™¤è„šæœ¬å’Œæ ·å¼å†…å®¹
    for tag in soup(['script', 'style', 'noscript', 'meta', 'link']):
        tag.decompose()

    # è·å–çº¯æ–‡æœ¬ï¼ˆä¿ç•™alt/textç­‰å±æ€§ï¼‰
    text = soup.get_text(separator=' ', strip=True)

    # æ‰§è¡Œç²¾ç¡®åˆ†è¯
    words = jieba.lcut(text)
    print("ã€ç²¾ç¡®åˆ†è¯ç»“æœã€‘", "/".join(words))

    # ç”Ÿæˆæ£€æµ‹ç»“æœ
    return {kw: kw in words for kw in keywords}
print("ğŸ“„ åŸå§‹HTMLç‰‡æ®µï¼š")
print(test_html.strip().replace('\n', ' '))
print("\nğŸ” æ£€æµ‹ç»“æœï¼š")
result = check_html_exist_kw(test_html, keywords)
print({k: "âœ…å­˜åœ¨" if v else "âŒä¸å­˜åœ¨" for k, v in result.items()})